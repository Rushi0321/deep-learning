{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7e8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is deep learning section diff from the machine learning...\n",
    "#here we use human like neural structure to build model for classification and regression...\n",
    "#also process of data cleaning and other are same but model building and libraries are diffrent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1feaa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf#important library for deep learning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec5509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91916\\AppData\\Local\\Temp\\ipykernel_18620\\3907407629.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt#library for hyperparameter tuning\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kerastuner as kt#library for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b05e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b269fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values and dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ef88af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b238f520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5588cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no null values and no object type data so lets move forward by scaling values to -1 to 1 by mon max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba83e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf5e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0234fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6330d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values#all column except last target col\n",
    "y=df.iloc[:,-1].values#only target col in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34e16c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling x data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de2d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled=scale.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ba150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7117e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f68dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a0135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now import libraries from tensorflow that need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d2eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ddde11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af1ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras and from keras import sequential,dense and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd9d9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model without hyperparametr tuning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cebcf6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,activation='relu',input_shape=(8,)))#input layer....\n",
    "model.add(Dense(1,activation='sigmoid'))#last op layer\n",
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0dad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making model fit on the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d74e4987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7821 - val_loss: 0.4455 - val_accuracy: 0.7922\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7858 - val_loss: 0.4444 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7877 - val_loss: 0.4463 - val_accuracy: 0.7965\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7821 - val_loss: 0.4459 - val_accuracy: 0.7965\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7877 - val_loss: 0.4444 - val_accuracy: 0.7965\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7840 - val_loss: 0.4455 - val_accuracy: 0.7965\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7858 - val_loss: 0.4451 - val_accuracy: 0.7922\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7877 - val_loss: 0.4434 - val_accuracy: 0.7835\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7896 - val_loss: 0.4447 - val_accuracy: 0.7965\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7840 - val_loss: 0.4434 - val_accuracy: 0.7965\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7821 - val_loss: 0.4444 - val_accuracy: 0.7965\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7840 - val_loss: 0.4426 - val_accuracy: 0.7835\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7840 - val_loss: 0.4437 - val_accuracy: 0.7965\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7896 - val_loss: 0.4429 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7784 - val_loss: 0.4447 - val_accuracy: 0.7965\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7840 - val_loss: 0.4432 - val_accuracy: 0.7965\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7840 - val_loss: 0.4422 - val_accuracy: 0.7965\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7933 - val_loss: 0.4421 - val_accuracy: 0.8009\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7803 - val_loss: 0.4429 - val_accuracy: 0.7965\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7877 - val_loss: 0.4421 - val_accuracy: 0.7965\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7803 - val_loss: 0.4408 - val_accuracy: 0.7965\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7728 - val_loss: 0.4465 - val_accuracy: 0.7965\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7821 - val_loss: 0.4429 - val_accuracy: 0.7965\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7840 - val_loss: 0.4414 - val_accuracy: 0.7965\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7896 - val_loss: 0.4421 - val_accuracy: 0.7965\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7840 - val_loss: 0.4414 - val_accuracy: 0.7965\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7840 - val_loss: 0.4425 - val_accuracy: 0.7965\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7840 - val_loss: 0.4401 - val_accuracy: 0.8009\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7840 - val_loss: 0.4417 - val_accuracy: 0.7965\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7840 - val_loss: 0.4408 - val_accuracy: 0.7965\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7821 - val_loss: 0.4406 - val_accuracy: 0.7965\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7840 - val_loss: 0.4425 - val_accuracy: 0.7965\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7840 - val_loss: 0.4427 - val_accuracy: 0.7965\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7840 - val_loss: 0.4408 - val_accuracy: 0.7965\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7840 - val_loss: 0.4416 - val_accuracy: 0.7965\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7821 - val_loss: 0.4402 - val_accuracy: 0.7965\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7858 - val_loss: 0.4413 - val_accuracy: 0.7965\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7784 - val_loss: 0.4416 - val_accuracy: 0.7965\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7821 - val_loss: 0.4394 - val_accuracy: 0.7965\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7877 - val_loss: 0.4428 - val_accuracy: 0.7965\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7765 - val_loss: 0.4389 - val_accuracy: 0.7965\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7821 - val_loss: 0.4419 - val_accuracy: 0.7965\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7821 - val_loss: 0.4386 - val_accuracy: 0.8009\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7858 - val_loss: 0.4422 - val_accuracy: 0.7965\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7821 - val_loss: 0.4402 - val_accuracy: 0.8009\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7821 - val_loss: 0.4398 - val_accuracy: 0.8009\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7728 - val_loss: 0.4381 - val_accuracy: 0.8009\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7803 - val_loss: 0.4419 - val_accuracy: 0.7965\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7821 - val_loss: 0.4385 - val_accuracy: 0.7965\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7840 - val_loss: 0.4387 - val_accuracy: 0.7965\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7803 - val_loss: 0.4384 - val_accuracy: 0.8009\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7858 - val_loss: 0.4426 - val_accuracy: 0.7965\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7821 - val_loss: 0.4390 - val_accuracy: 0.7965\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7803 - val_loss: 0.4393 - val_accuracy: 0.7965\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7840 - val_loss: 0.4389 - val_accuracy: 0.7965\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7821 - val_loss: 0.4386 - val_accuracy: 0.7965\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7821 - val_loss: 0.4396 - val_accuracy: 0.8009\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7803 - val_loss: 0.4389 - val_accuracy: 0.7965\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7877 - val_loss: 0.4383 - val_accuracy: 0.7965\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7840 - val_loss: 0.4390 - val_accuracy: 0.7965\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7840 - val_loss: 0.4393 - val_accuracy: 0.7965\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7896 - val_loss: 0.4379 - val_accuracy: 0.8009\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7803 - val_loss: 0.4394 - val_accuracy: 0.7965\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7803 - val_loss: 0.4380 - val_accuracy: 0.8009\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7803 - val_loss: 0.4398 - val_accuracy: 0.8009\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7840 - val_loss: 0.4384 - val_accuracy: 0.7965\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7821 - val_loss: 0.4401 - val_accuracy: 0.8009\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7840 - val_loss: 0.4396 - val_accuracy: 0.8009\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7784 - val_loss: 0.4375 - val_accuracy: 0.8009\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7858 - val_loss: 0.4395 - val_accuracy: 0.8009\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7821 - val_loss: 0.4384 - val_accuracy: 0.7965\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7765 - val_loss: 0.4378 - val_accuracy: 0.8009\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7803 - val_loss: 0.4383 - val_accuracy: 0.7965\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7840 - val_loss: 0.4386 - val_accuracy: 0.7965\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7877 - val_loss: 0.4389 - val_accuracy: 0.7965\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7877 - val_loss: 0.4372 - val_accuracy: 0.8009\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7877 - val_loss: 0.4376 - val_accuracy: 0.8009\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7840 - val_loss: 0.4390 - val_accuracy: 0.7965\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7840 - val_loss: 0.4370 - val_accuracy: 0.8009\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7858 - val_loss: 0.4377 - val_accuracy: 0.8009\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7803 - val_loss: 0.4376 - val_accuracy: 0.7922\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7784 - val_loss: 0.4373 - val_accuracy: 0.7965\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7877 - val_loss: 0.4379 - val_accuracy: 0.7965\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.4379 - val_accuracy: 0.7965\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7821 - val_loss: 0.4378 - val_accuracy: 0.7922\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7821 - val_loss: 0.4379 - val_accuracy: 0.7965\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7840 - val_loss: 0.4377 - val_accuracy: 0.7965\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7877 - val_loss: 0.4368 - val_accuracy: 0.7965\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7803 - val_loss: 0.4372 - val_accuracy: 0.8009\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7858 - val_loss: 0.4408 - val_accuracy: 0.8009\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7821 - val_loss: 0.4360 - val_accuracy: 0.8052\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7858 - val_loss: 0.4378 - val_accuracy: 0.7965\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7840 - val_loss: 0.4380 - val_accuracy: 0.7965\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7840 - val_loss: 0.4377 - val_accuracy: 0.7965\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7840 - val_loss: 0.4375 - val_accuracy: 0.7922\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7877 - val_loss: 0.4365 - val_accuracy: 0.7965\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7821 - val_loss: 0.4376 - val_accuracy: 0.7965\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7896 - val_loss: 0.4369 - val_accuracy: 0.7965\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7858 - val_loss: 0.4363 - val_accuracy: 0.7965\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7747 - val_loss: 0.4374 - val_accuracy: 0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f2034f970>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0f75a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now with hyperparametr tuning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c795bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model=Sequential()\n",
    "  counter=0\n",
    "  for i in range(hp.Int(\"num_layers\",min_value=1,max_value=10)):#no of hidden layers from 1 to 9...\n",
    "    if counter==0:\n",
    "      model.add(\n",
    "          Dense(\n",
    "              units=hp.Int(\"units\"+str(i),min_value=8,max_value=128,step=8), #no of neurons in 1st hidden layer....\n",
    "              activation=hp.Choice('Activation'+str(i),values=['relu','tanh','sigmoid']),#best optimizer from no of optimizers\n",
    "              input_dim=8)\n",
    "      )\n",
    "      \n",
    "    else:\n",
    "      model.add(\n",
    "          Dense(\n",
    "              units=hp.Int(\"units\"+str(i),min_value=8,max_value=128,step=8),\n",
    "              activation=hp.Choice('Activation'+str(i),values=['relu','tanh','sigmoid']),\n",
    "              )\n",
    "      )\n",
    "    counter+=1\n",
    "  model.add(Dense(1,activation='sigmoid')) #designing output model.....\n",
    "  optimizer=hp.Choice(\"optimizer\",values=['adam','rmsprop','adadelta','sgd','nadam']) #optimizer for output layer....\n",
    "  model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy']) #now compiling model...\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "950ea83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuning\\version4\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuning\\version4\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner=kt.RandomSearch(build_model,objective=\"val_accuracy\",max_trials=3,directory='tuning',project_name='version4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c955a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now passing data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0888ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3902761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting best model values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec45d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 6,\n",
       " 'units0': 112,\n",
       " 'Activation0': 'tanh',\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 80,\n",
       " 'Activation1': 'sigmoid',\n",
       " 'units2': 24,\n",
       " 'Activation2': 'tanh',\n",
       " 'units3': 64,\n",
       " 'Activation3': 'sigmoid',\n",
       " 'units4': 24,\n",
       " 'Activation4': 'relu',\n",
       " 'units5': 72,\n",
       " 'Activation5': 'tanh',\n",
       " 'units6': 80,\n",
       " 'Activation6': 'tanh',\n",
       " 'units7': 120,\n",
       " 'Activation7': 'sigmoid',\n",
       " 'units8': 72,\n",
       " 'Activation8': 'relu',\n",
       " 'units9': 8,\n",
       " 'Activation9': 'relu'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b57248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now storing model with best parameter in 0 index..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "385df6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae8db053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 112)               1008      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                9040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1944      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1600      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 72)                1800      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,025\n",
      "Trainable params: 17,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "035af499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now fitting data to best parametrised model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a49210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.6688 - accuracy: 0.5531 - val_loss: 0.6292 - val_accuracy: 0.6320\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.6797 - val_loss: 0.5998 - val_accuracy: 0.6320\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6667 - val_loss: 0.5653 - val_accuracy: 0.7143\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7076 - val_loss: 0.5619 - val_accuracy: 0.6710\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7281 - val_loss: 0.5242 - val_accuracy: 0.7316\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7393 - val_loss: 0.5921 - val_accuracy: 0.6926\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7430 - val_loss: 0.5030 - val_accuracy: 0.7489\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7449 - val_loss: 0.4776 - val_accuracy: 0.7835\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7505 - val_loss: 0.4736 - val_accuracy: 0.7835\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7486 - val_loss: 0.4665 - val_accuracy: 0.7922\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7561 - val_loss: 0.4638 - val_accuracy: 0.7835\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7542 - val_loss: 0.5529 - val_accuracy: 0.7186\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7430 - val_loss: 0.4695 - val_accuracy: 0.7835\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7598 - val_loss: 0.4676 - val_accuracy: 0.7835\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7709 - val_loss: 0.4816 - val_accuracy: 0.7835\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7542 - val_loss: 0.4571 - val_accuracy: 0.7835\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7840 - val_loss: 0.4666 - val_accuracy: 0.7965\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7672 - val_loss: 0.4586 - val_accuracy: 0.7879\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7561 - val_loss: 0.4592 - val_accuracy: 0.7965\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7579 - val_loss: 0.4545 - val_accuracy: 0.7879\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7579 - val_loss: 0.4517 - val_accuracy: 0.7879\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7374 - val_loss: 0.4584 - val_accuracy: 0.7879\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7616 - val_loss: 0.4543 - val_accuracy: 0.7879\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7616 - val_loss: 0.4656 - val_accuracy: 0.7835\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7635 - val_loss: 0.4590 - val_accuracy: 0.7835\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7672 - val_loss: 0.4608 - val_accuracy: 0.7965\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7561 - val_loss: 0.4533 - val_accuracy: 0.7879\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7635 - val_loss: 0.4538 - val_accuracy: 0.7835\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7244 - val_loss: 0.4635 - val_accuracy: 0.8052\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7542 - val_loss: 0.5153 - val_accuracy: 0.7532\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7616 - val_loss: 0.4616 - val_accuracy: 0.7879\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7654 - val_loss: 0.4575 - val_accuracy: 0.7835\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.4610 - val_accuracy: 0.7879\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7598 - val_loss: 0.4720 - val_accuracy: 0.7749\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7672 - val_loss: 0.4664 - val_accuracy: 0.7835\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7691 - val_loss: 0.4666 - val_accuracy: 0.7792\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7598 - val_loss: 0.4580 - val_accuracy: 0.8009\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7579 - val_loss: 0.4554 - val_accuracy: 0.7835\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7542 - val_loss: 0.4599 - val_accuracy: 0.7879\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7654 - val_loss: 0.5312 - val_accuracy: 0.7532\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7654 - val_loss: 0.4596 - val_accuracy: 0.7922\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7598 - val_loss: 0.4519 - val_accuracy: 0.7922\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7523 - val_loss: 0.4813 - val_accuracy: 0.7879\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7747 - val_loss: 0.4524 - val_accuracy: 0.7922\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7579 - val_loss: 0.5162 - val_accuracy: 0.7489\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7356 - val_loss: 0.4900 - val_accuracy: 0.7792\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7561 - val_loss: 0.4554 - val_accuracy: 0.7879\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7616 - val_loss: 0.4662 - val_accuracy: 0.8139\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7579 - val_loss: 0.4616 - val_accuracy: 0.7835\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7486 - val_loss: 0.4515 - val_accuracy: 0.7879\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7598 - val_loss: 0.4590 - val_accuracy: 0.7835\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7747 - val_loss: 0.4526 - val_accuracy: 0.7922\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7579 - val_loss: 0.4556 - val_accuracy: 0.7835\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7579 - val_loss: 0.4589 - val_accuracy: 0.7835\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7728 - val_loss: 0.4557 - val_accuracy: 0.8009\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7728 - val_loss: 0.4531 - val_accuracy: 0.7922\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7691 - val_loss: 0.4512 - val_accuracy: 0.7835\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7672 - val_loss: 0.4830 - val_accuracy: 0.7792\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7598 - val_loss: 0.4531 - val_accuracy: 0.7879\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7672 - val_loss: 0.4644 - val_accuracy: 0.8052\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.4539 - val_accuracy: 0.8009\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7616 - val_loss: 0.4522 - val_accuracy: 0.7835\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7561 - val_loss: 0.4557 - val_accuracy: 0.7835\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7523 - val_loss: 0.4712 - val_accuracy: 0.7879\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7598 - val_loss: 0.4502 - val_accuracy: 0.7879\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7709 - val_loss: 0.4506 - val_accuracy: 0.7879\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7635 - val_loss: 0.4562 - val_accuracy: 0.8139\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7672 - val_loss: 0.4645 - val_accuracy: 0.8052\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7561 - val_loss: 0.4528 - val_accuracy: 0.7922\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7505 - val_loss: 0.4515 - val_accuracy: 0.7879\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7561 - val_loss: 0.4797 - val_accuracy: 0.7792\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7579 - val_loss: 0.4505 - val_accuracy: 0.7879\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7561 - val_loss: 0.4607 - val_accuracy: 0.7835\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7542 - val_loss: 0.4632 - val_accuracy: 0.7835\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7654 - val_loss: 0.4728 - val_accuracy: 0.7835\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7728 - val_loss: 0.4513 - val_accuracy: 0.7879\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7747 - val_loss: 0.4610 - val_accuracy: 0.8052\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7672 - val_loss: 0.4510 - val_accuracy: 0.7965\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.7749\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7598 - val_loss: 0.4732 - val_accuracy: 0.7792\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7635 - val_loss: 0.4544 - val_accuracy: 0.7879\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7542 - val_loss: 0.4607 - val_accuracy: 0.8052\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7672 - val_loss: 0.4570 - val_accuracy: 0.7965\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7654 - val_loss: 0.4553 - val_accuracy: 0.7965\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7635 - val_loss: 0.4522 - val_accuracy: 0.7879\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7709 - val_loss: 0.4524 - val_accuracy: 0.7879\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7598 - val_loss: 0.4594 - val_accuracy: 0.7792\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7579 - val_loss: 0.4511 - val_accuracy: 0.7922\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7765 - val_loss: 0.4670 - val_accuracy: 0.8095\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4546 - val_accuracy: 0.7879\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7579 - val_loss: 0.4622 - val_accuracy: 0.7879\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7598 - val_loss: 0.4546 - val_accuracy: 0.7835\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7654 - val_loss: 0.4503 - val_accuracy: 0.7922\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7803 - val_loss: 0.4486 - val_accuracy: 0.7835\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7803 - val_loss: 0.4489 - val_accuracy: 0.7922\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7672 - val_loss: 0.4487 - val_accuracy: 0.7922\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7505 - val_loss: 0.4626 - val_accuracy: 0.7879\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7672 - val_loss: 0.4486 - val_accuracy: 0.8009\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7598 - val_loss: 0.4569 - val_accuracy: 0.8095\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7709 - val_loss: 0.4568 - val_accuracy: 0.7879\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7765 - val_loss: 0.4463 - val_accuracy: 0.7879\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7654 - val_loss: 0.4461 - val_accuracy: 0.7922\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4510 - val_accuracy: 0.7879\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4456 - val_accuracy: 0.7879\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7765 - val_loss: 0.4450 - val_accuracy: 0.7879\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7654 - val_loss: 0.4456 - val_accuracy: 0.7879\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7579 - val_loss: 0.4464 - val_accuracy: 0.8009\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7505 - val_loss: 0.4711 - val_accuracy: 0.7965\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7579 - val_loss: 0.4610 - val_accuracy: 0.8182\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7561 - val_loss: 0.4454 - val_accuracy: 0.7922\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7654 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7672 - val_loss: 0.4452 - val_accuracy: 0.7965\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7747 - val_loss: 0.4438 - val_accuracy: 0.7922\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7747 - val_loss: 0.4423 - val_accuracy: 0.7879\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7654 - val_loss: 0.4425 - val_accuracy: 0.7835\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7784 - val_loss: 0.4506 - val_accuracy: 0.7879\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7486 - val_loss: 0.4921 - val_accuracy: 0.7706\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7616 - val_loss: 0.4425 - val_accuracy: 0.8052\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7672 - val_loss: 0.4578 - val_accuracy: 0.7922\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7803 - val_loss: 0.4401 - val_accuracy: 0.7835\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7709 - val_loss: 0.4403 - val_accuracy: 0.8139\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7784 - val_loss: 0.4486 - val_accuracy: 0.8182\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7821 - val_loss: 0.4651 - val_accuracy: 0.8009\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7728 - val_loss: 0.4434 - val_accuracy: 0.7922\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7784 - val_loss: 0.4388 - val_accuracy: 0.7879\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7542 - val_loss: 0.4571 - val_accuracy: 0.8052\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7691 - val_loss: 0.4496 - val_accuracy: 0.8139\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4379 - val_accuracy: 0.8095\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7616 - val_loss: 0.4480 - val_accuracy: 0.7922\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7728 - val_loss: 0.4340 - val_accuracy: 0.8052\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7821 - val_loss: 0.4511 - val_accuracy: 0.7922\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7635 - val_loss: 0.4358 - val_accuracy: 0.8139\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7654 - val_loss: 0.4331 - val_accuracy: 0.8009\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7709 - val_loss: 0.4314 - val_accuracy: 0.8009\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7728 - val_loss: 0.4346 - val_accuracy: 0.8182\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7821 - val_loss: 0.4370 - val_accuracy: 0.8139\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7840 - val_loss: 0.4371 - val_accuracy: 0.8009\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7784 - val_loss: 0.4466 - val_accuracy: 0.8009\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7635 - val_loss: 0.4330 - val_accuracy: 0.8095\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7728 - val_loss: 0.4372 - val_accuracy: 0.8009\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7728 - val_loss: 0.4341 - val_accuracy: 0.8052\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7616 - val_loss: 0.4416 - val_accuracy: 0.8095\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7765 - val_loss: 0.4526 - val_accuracy: 0.7965\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7803 - val_loss: 0.4467 - val_accuracy: 0.8009\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7598 - val_loss: 0.4385 - val_accuracy: 0.8095\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7765 - val_loss: 0.4377 - val_accuracy: 0.8139\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7803 - val_loss: 0.4499 - val_accuracy: 0.7965\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7765 - val_loss: 0.4442 - val_accuracy: 0.8052\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7896 - val_loss: 0.4636 - val_accuracy: 0.8052\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7374 - val_loss: 0.4345 - val_accuracy: 0.8052\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7784 - val_loss: 0.4314 - val_accuracy: 0.8052\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7803 - val_loss: 0.4321 - val_accuracy: 0.8095\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7840 - val_loss: 0.4358 - val_accuracy: 0.8052\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7616 - val_loss: 0.4296 - val_accuracy: 0.8009\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7765 - val_loss: 0.4327 - val_accuracy: 0.8139\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7747 - val_loss: 0.4380 - val_accuracy: 0.8052\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7747 - val_loss: 0.4402 - val_accuracy: 0.8095\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7803 - val_loss: 0.4322 - val_accuracy: 0.8139\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7765 - val_loss: 0.4396 - val_accuracy: 0.8052\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7803 - val_loss: 0.4349 - val_accuracy: 0.8009\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7821 - val_loss: 0.4277 - val_accuracy: 0.8095\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7765 - val_loss: 0.4308 - val_accuracy: 0.8139\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7747 - val_loss: 0.4297 - val_accuracy: 0.8095\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7672 - val_loss: 0.4288 - val_accuracy: 0.7965\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7747 - val_loss: 0.4279 - val_accuracy: 0.8009\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7784 - val_loss: 0.4284 - val_accuracy: 0.8052\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7803 - val_loss: 0.4374 - val_accuracy: 0.8052\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7877 - val_loss: 0.4821 - val_accuracy: 0.7792\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7765 - val_loss: 0.4277 - val_accuracy: 0.8009\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7709 - val_loss: 0.4284 - val_accuracy: 0.8095\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7858 - val_loss: 0.4274 - val_accuracy: 0.8009\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7803 - val_loss: 0.4379 - val_accuracy: 0.8052\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7821 - val_loss: 0.4314 - val_accuracy: 0.8095\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7747 - val_loss: 0.4280 - val_accuracy: 0.8139\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7728 - val_loss: 0.4476 - val_accuracy: 0.8052\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7896 - val_loss: 0.4285 - val_accuracy: 0.8095\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7709 - val_loss: 0.4341 - val_accuracy: 0.8009\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7635 - val_loss: 0.4408 - val_accuracy: 0.8009\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7821 - val_loss: 0.4436 - val_accuracy: 0.8052\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7858 - val_loss: 0.4292 - val_accuracy: 0.8009\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7840 - val_loss: 0.4308 - val_accuracy: 0.7965\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7765 - val_loss: 0.4283 - val_accuracy: 0.8139\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7821 - val_loss: 0.4364 - val_accuracy: 0.8052\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7784 - val_loss: 0.4331 - val_accuracy: 0.8139\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7672 - val_loss: 0.4296 - val_accuracy: 0.8095\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7709 - val_loss: 0.4456 - val_accuracy: 0.7922\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7821 - val_loss: 0.4346 - val_accuracy: 0.8139\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.4309 - val_accuracy: 0.8009\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7728 - val_loss: 0.4279 - val_accuracy: 0.7965\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7784 - val_loss: 0.4334 - val_accuracy: 0.7965\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7616 - val_loss: 0.4293 - val_accuracy: 0.8009\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7672 - val_loss: 0.4296 - val_accuracy: 0.8009\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7803 - val_loss: 0.4377 - val_accuracy: 0.7922\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7784 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7747 - val_loss: 0.4277 - val_accuracy: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f1fffd4c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,y_train,epochs=200,initial_epoch=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fea122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 112)               1008      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                9040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1944      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1600      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 72)                1800      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,025\n",
      "Trainable params: 17,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea43090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
